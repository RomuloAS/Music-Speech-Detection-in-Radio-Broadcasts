{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Optimisation, Pre-/Post-processing, Cost-sensitive Learning, Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing \n",
    "\n",
    "* [loadarff (scify)][loadarff]: Read an arff file.\n",
    "* [glob][glob]: The glob module finds all the pathnames matching a specified pattern.\n",
    "* [pandas][pandas]: Pandas stands for â€œPython Data Analysis Library\".\n",
    "* [scikit joblib][joblib]: Joblib is a set of tools to provide lightweight pipelining in Python.\n",
    "* [warnings][warnings]: It filters warnings messages, and ignores them.\n",
    "* [pathlib][pathlib]: This module offers classes representing filesystem paths with semantics appropriate for different operating systems.\n",
    "\n",
    "[loadarff]:https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.arff.loadarff.html\n",
    "[glob]:https://docs.python.org/3/library/glob.html\n",
    "[pandas]:http://pandas.pydata.org/pandas-docs/stable/\n",
    "[joblib]:https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "[warnings]:https://docs.python.org/3/library/warnings.html#warnings.filterwarnings\n",
    "[pathlib]:https://docs.python.org/3/library/pathlib.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import pathlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Loading\n",
    "\n",
    "Read all files inside \"Test\" folder, and sort list of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = glob(\"../Test/*.arff\", recursive=True)\n",
    "ff = sorted(ff, key=lambda x: int(''.join(filter(str.isdigit, x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select speech files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_files = []\n",
    "\n",
    "for f in ff:\n",
    "    if \"speech\" in f:\n",
    "        speech_files.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Classifiers\n",
    "\n",
    "Load ensemble and stack classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = joblib.load(\"stack_speech.pkl\")\n",
    "ensemble = joblib.load(\"ensemble_speech.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting variable cols\n",
    "\n",
    "Set variable cols because stack was fitted with a specific number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['f000002', 'f000003', 'f000010', 'f000014', 'f000018', 'f000022', 'f000026', 'f000027', 'f000029', 'f000032', 'f000035', 'f000038', 'f000041', 'f000044', 'f000046', 'f000048', 'f000049', 'f000050', 'f000051', 'f000052', 'f000053', 'f000054', 'f000055', 'f000057', 'f000058', 'f000059', 'f000060', 'f000061', 'f000062', 'f000063', 'f000064', 'f000065', 'f000066', 'f000067', 'f000068', 'f000069', 'f000070', 'f000071', 'f000072', 'f000073', 'f000074', 'f000075', 'f000076', 'f000077', 'f000078', 'f000079', 'f000080', 'f000081', 'f000082', 'f000083', 'f000084', 'f000085', 'f000086', 'f000087', 'f000089', 'f000090', 'f000091', 'f000092', 'f000093', 'f000094', 'f000095', 'f000096', 'f000097', 'f000098', 'f000099', 'f000100', 'f000101', 'f000102', 'f000103']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech prediction\n",
    "\n",
    "Load arff files to pandas dataframe and predict speech or no speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from arff file: 15.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 15.speech.txt\n",
      "\n",
      "Loading data from arff file: 16.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 16.speech.txt\n",
      "\n",
      "Loading data from arff file: 17.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 17.speech.txt\n",
      "\n",
      "Loading data from arff file: 18.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 18.speech.txt\n",
      "\n",
      "Loading data from arff file: 19.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 19.speech.txt\n",
      "\n",
      "Loading data from arff file: 20.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 20.speech.txt\n",
      "\n",
      "Loading data from arff file: 21.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 21.speech.txt\n",
      "\n",
      "Loading data from arff file: 22.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 22.speech.txt\n",
      "\n",
      "Loading data from arff file: 23.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 23.speech.txt\n",
      "\n",
      "Loading data from arff file: 24.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 24.speech.txt\n",
      "\n",
      "Loading data from arff file: 25.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 25.speech.txt\n",
      "\n",
      "Loading data from arff file: 26.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 26.speech.txt\n",
      "\n",
      "Loading data from arff file: 27.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 27.speech.txt\n",
      "\n",
      "Loading data from arff file: 28.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 28.speech.txt\n",
      "\n",
      "Loading data from arff file: 29.speech.arff\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [BC: BaggingClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [RF: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: LGBMClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "saving prediction file: 29.speech.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create new folder for predictions\n",
    "path = \"../Prediction/Speech/\"\n",
    "pathlib.Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for f in speech_files: \n",
    "    with open(f) as arff:\n",
    "        \n",
    "        ### Load data\n",
    "        print(\"Loading data from arff file:\", f.split(\"/\")[-1])\n",
    "        data, meta = loadarff(arff)\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        ### Convert to stack format and predict\n",
    "        S = stack.transform(df[cols])\n",
    "        pred = ensemble.predict(S)\n",
    "        \n",
    "        ### format prediction\n",
    "        speech_prediction = [\"1\" if i == 1 else \"0\" for i in pred]\n",
    "        \n",
    "        ### Write file with predictions\n",
    "        name = f.split(\"/\")[-1]\n",
    "        name = \".\".join(name.split(\".\")[:-1]) + \".txt\"\n",
    "        print(\"saving prediction file:\", name, end=\"\\n\\n\")\n",
    "        with open(path + name, \"w\") as pred_file:\n",
    "            pred_file.write(\"\\n\".join(speech_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 3)\n",
    "plt.yticks([], [])\n",
    "plt.bar(range(len(speech_prediction)), speech_prediction, width=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 3)\n",
    "plt.yticks([], [])\n",
    "plt.bar(range(len(df[\"class\"])), df[\"class\"], width=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '1']\n",
      "0    b'speech'\n",
      "1    b'speech'\n",
      "2    b'speech'\n",
      "3    b'speech'\n",
      "4    b'speech'\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(speech_prediction[:5])\n",
    "print(df[\"class\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
